Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,131.88679245283018,-0.9641366,-0.990566038017003,-0.990566038017003,1.0
20000,1.4189383,137.5,-0.9588502,-0.9974193551367329,-0.9974193551367329,1.0
30000,1.4170039,156.77142857142857,-0.74154896,-0.9635743618011474,-0.9635743618011474,1.0
40000,1.416902,903.5555555555555,-0.72475135,-0.628253804312812,-0.628253804312812,1.0
50000,1.4158531,644.4736842105264,-0.63701296,-0.7894736842105263,-0.7894736842105263,1.0
60000,1.4157251,773.3846153846154,-0.63030493,-0.6593636503586402,-0.6593636503586402,1.0
70000,1.4146199,576.7058823529412,-0.5594502,-0.7647058823529411,-0.7647058823529411,1.0
80000,1.414316,716.4615384615385,-0.52485764,-0.6669230782068692,-0.6669230782068692,1.0
90000,1.4126157,521.6875,-0.48195058,-0.8125,-0.8125,1.0
100000,1.4121114,815.1428571428571,-0.458573,-0.611601152590343,-0.611601152590343,1.0
110000,1.4123005,1497.8333333333333,-0.40060443,-0.3333333333333333,-0.3333333333333333,1.0
120000,1.4123977,1018.7,-0.38900524,-0.5,-0.5,1.0
130000,1.4123327,1550.75,-0.3386236,-0.25,-0.25,1.0
140000,1.4122989,1666.3333333333333,-0.31667542,-0.16666666666666666,-0.16666666666666666,1.0
150000,1.4110701,1756.875,-0.28421542,-0.125,-0.125,1.0
160000,1.4100858,1679.0,-0.26194805,-0.16666666666666666,-0.16666666666666666,1.0
170000,1.4099237,1464.5,-0.24998415,-0.3333333333333333,-0.3333333333333333,1.0
180000,1.409786,1999.0,-0.22912776,0.0,0.0,1.0
